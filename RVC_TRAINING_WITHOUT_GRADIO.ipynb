{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "wDc36qTLWJFr",
        "otjrpJm4gcTN"
      ],
      "authorship_tag": "ABX9TyOpByAsTyDjlgMIAYPUYxMS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filispeen/retrieval-based-voice-conversion-colab/blob/main/RVC_TRAINING_WITHOUT_GRADIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vCrvpsQTUM_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount(\"/content/drive\")\n",
        "debug = False # @param {type:\"boolean\"}\n",
        "\n",
        "!apt install -y aria2\n",
        "%cd /content\n",
        "!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git ./RVC\n",
        "%cd RVC/\n",
        "\n",
        "if not debug:\n",
        "  !pip install -q -r requirements.txt\n",
        "else:\n",
        "  !pip install -r requirements.txt\n",
        "\n",
        "with open(\"./tools/dlmodels.sh\", \"r\") as f:\n",
        "  dlmodels=f.read()\n",
        "dlmodels=dlmodels.replace('read -p \"Press any key to continue...\" -n1 -s', \"\")\n",
        "with open(\"./tools/dlmodels.sh\", \"w\") as f:\n",
        "  f.write(dlmodels)\n",
        "!./tools/dlmodels.sh\n",
        "\n",
        "%cd configs\n",
        "for fil in os.lisdir():\n",
        "  with open(fil, \"r\") as f:\n",
        "    config=f.read()\n",
        "\n",
        "  config=config.replace('\"log_interval\": 200,', '\"log_interval\": 30,')\n",
        "\n",
        "  with open(fil, \"w\") as f:\n",
        "    f.write(config)\n",
        "%cd ../\n",
        "\n",
        "if not debug:\n",
        "  clear_output()\n",
        "\n",
        "#%cd /content\n",
        "#!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git ./RVC\n",
        "#%cd RVC/\n",
        "#if not debug:\n",
        "#  !pip install -q -r requirements.txt\n",
        "#else:\n",
        "#  !pip install -r requirements.txt\n",
        "#!wget https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#%cd pretrained\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D32k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D40k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D48k.pth\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G32k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G40k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G48k.pth\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D32k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D40k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D48k.pth\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G32k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G40k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G48k.pth\n",
        "#%cd ../pretrained_v2\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D32k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D40k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D48k.pth\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G32k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G40k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G48k.pth\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D32k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D40k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D48k.pth\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G32k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G40k.pth && wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G48k.pth\n",
        "#%cd ../weights\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()\n",
        "#\n",
        "#!wget -nc https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/weights/%E7%99%BD%E8%8F%9C357k.pt\n",
        "#%cd ../\n",
        "#\n",
        "#if not debug:\n",
        "#  clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown --------------------------------\n",
        "#@markdown **Step 1: Fill in the experimental configuration. Experimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.**\n",
        "\n",
        "#@markdown ***Name of archive is same with model name.***\n",
        "DATASET=\"/content/drive/MyDrive/PITONAI.zip\"  #@param {type:\"string\"}\n",
        "MODELNAME = DATASET[23:-4]\n",
        "INPDATASET=\"/content/dataset/\" + f\"{str(MODELNAME)}\"\n",
        "!mkdir -p \"{INPDATASET}\"\n",
        "!mkdir \"/content/RVC/logs/{MODELNAME}\"\n",
        "!unzip -d /content/dataset/{MODELNAME}/ -B {DATASET}\n",
        "!ls -a /content/dataset/\n",
        "for data in os.listdir(INPDATASET):\n",
        "  if data.endswith(\"~1\") or data.endswith(\"~2\") or data.endswith(\"~3\") or data.endswith(\"~4\") or data.endswith(\"~5\"):\n",
        "    !rm -rf \"{INPDATASET}/{data}\"\n",
        "\n",
        "#@markdown ***Number of CPU processes used for pitch extraction and data processing:***\n",
        "\n",
        "TARGET_SAMPLE_RATE = \"40k\" # @param [\"32k\", \"40k\", \"48k\"]\n",
        "#@markdown ***Whether the model has pitch guidance (required for singing, optional for speech):***\n",
        "PITCH_GUIDANCE = True #@param {type:\"boolean\"}\n",
        "SAMPLE_RATE_VERSION = \"v1\" # @param [\"v1\", \"v2\"]\n",
        "CPU_THREADS = 2  #@param {type:\"integer\"}\n",
        "if TARGET_SAMPLE_RATE==\"32k\" and SAMPLE_RATE_VERSION==\"v1\":\n",
        "  raise ValueError(\"32k Sample rate only in SAMPLE_RATE_VERSION: v2\")\n",
        "elif TARGET_SAMPLE_RATE==\"32k\" and not SAMPLE_RATE_VERSION==\"v1\":\n",
        "  TARGET_SAMPLE_RATE=32000\n",
        "if TARGET_SAMPLE_RATE==\"40k\":\n",
        "  TARGET_SAMPLE_RATE=40000\n",
        "if TARGET_SAMPLE_RATE==\"48k\":\n",
        "  TARGET_SAMPLE_RATE=48000\n",
        "if PITCH_GUIDANCE:\n",
        "  PITCH_GUIDANCE=1\n",
        "if not PITCH_GUIDANCE:\n",
        "  PITCH_GUIDANCE=0\n",
        "\n",
        "#@markdown --------------------------------\n",
        "#@markdown **Step 2: Use CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index):**\n",
        "\n",
        "#@markdown ***Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2:***\n",
        "GPU_INDEX = \"0\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ***Please specify the speaker/singer ID:***\n",
        "Speaker_ID = 0 # @param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "#@markdown ***Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'dio': improved speech but slower extraction; 'harvest': better quality but slower extraction):***\n",
        "EXTRACTION_ALGORITHM = \"harvest\" # @param [\"harvest\", \"dio\", \"pm\"]\n",
        "\n",
        "#@markdown --------------------------------\n",
        "#@markdown **Step 3: Fill in the training settings and start training the model and index**\n",
        "save_every_epoch = 5 # @param {type:\"integer\"}\n",
        "total_epoch = 20 # @param {type:\"integer\"}\n",
        "#@markdown *I recommend to set batch size 16~18*\n",
        "BATCH_SIZE_PER_GPU = 5 # @param {type:\"integer\"}\n",
        "#@markdown ***Save only the latest '.ckpt' file to save disk space:***\n",
        "SAVE_ONLY_LATEST_CKPT = False #@param {type:\"boolean\"}\n",
        "if SAVE_ONLY_LATEST_CKPT:\n",
        "  SAVE_ONLY_LATEST_CKPT=1\n",
        "if not SAVE_ONLY_LATEST_CKPT:\n",
        "  SAVE_ONLY_LATEST_CKPT=0\n",
        "#@markdown **Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement:**\n",
        "CACHE_ALL_TRAINING_SETS_TO_GPU_MEMORY = False #@param {type:\"boolean\"}\n",
        "if CACHE_ALL_TRAINING_SETS_TO_GPU_MEMORY:\n",
        "  CACHE_ALL_TRAINING_SETS_TO_GPU_MEMORY=1\n",
        "if not CACHE_ALL_TRAINING_SETS_TO_GPU_MEMORY:\n",
        "  CACHE_ALL_TRAINING_SETS_TO_GPU_MEMORY=0\n",
        "#@markdown ***Save a small final model to the 'weights' folder at each save point:***\n",
        "SAVE_A_SMALL_FINAL_MODEL = False #@param {type:\"boolean\"}\n",
        "if SAVE_A_SMALL_FINAL_MODEL:\n",
        "  SAVE_A_SMALL_FINAL_MODEL=1\n",
        "if not SAVE_A_SMALL_FINAL_MODEL:\n",
        "  SAVE_A_SMALL_FINAL_MODEL=0\n",
        "#@markdown --------------------------------\n",
        "\n",
        "\n",
        "if PITCH_GUIDANCE==1:\n",
        "  if TARGET_SAMPLE_RATE==32000 and SAMPLE_RATE_VERSION==\"v1\":\n",
        "    raise ValueError(\"32k Sample rate only in SAMPLE_RATE_VERSION: v2\")\n",
        "  if TARGET_SAMPLE_RATE==40000 and SAMPLE_RATE_VERSION==\"v1\":\n",
        "    G = \"pretrained/f0G40k.pth\"\n",
        "    D = \"pretrained/f0D40k.pth\"\n",
        "  if TARGET_SAMPLE_RATE==48000 and SAMPLE_RATE_VERSION==\"v1\":\n",
        "    G = \"pretrained/f0G48k.pth\"\n",
        "    D = \"pretrained/f0D48k.pth\"\n",
        "  if TARGET_SAMPLE_RATE==32000 and SAMPLE_RATE_VERSION==\"v2\":\n",
        "    G = \"pretrained_v2/f0G32k.pth\"\n",
        "    D = \"pretrained_v2/f0D32k.pth\"\n",
        "  if TARGET_SAMPLE_RATE==40000 and SAMPLE_RATE_VERSION==\"v2\":\n",
        "    G = \"pretrained_v2/f0G40k.pth\"\n",
        "    D = \"pretrained_v2/f0D40k.pth\"\n",
        "  if TARGET_SAMPLE_RATE==48000 and SAMPLE_RATE_VERSION==\"v2\":\n",
        "    G = \"pretrained_v2/f0G48k.pth\"\n",
        "    D = \"pretrained_v2/f0D48k.pth\"\n",
        "if PITCH_GUIDANCE==1:\n",
        "  if TARGET_SAMPLE_RATE==32000 and SAMPLE_RATE_VERSION==\"v1\":\n",
        "    raise ValueError(\"32k Sample rate only in SAMPLE_RATE_VERSION: v2\")\n",
        "  if TARGET_SAMPLE_RATE==40000 and SAMPLE_RATE_VERSION==\"v1\":\n",
        "    G = \"pretrained/G40k.pth\"\n",
        "    D = \"pretrained/D40k.pth\"\n",
        "  if TARGET_SAMPLE_RATE==48000 and SAMPLE_RATE_VERSION==\"v1\":\n",
        "    G = \"pretrained/G48k.pth\"\n",
        "    D = \"pretrained/D48k.pth\"\n",
        "  if TARGET_SAMPLE_RATE==32000 and SAMPLE_RATE_VERSION==\"v2\":\n",
        "    G = \"pretrained_v2/G32k.pth\"\n",
        "    D = \"pretrained_v2/D32k.pth\"\n",
        "  if TARGET_SAMPLE_RATE==40000 and SAMPLE_RATE_VERSION==\"v2\":\n",
        "    G = \"pretrained_v2/G40k.pth\"\n",
        "    D = \"pretrained_v2/D40k.pth\"\n",
        "  if TARGET_SAMPLE_RATE==48000 and SAMPLE_RATE_VERSION==\"v2\":\n",
        "    G = \"pretrained_v2/G48k.pth\"\n",
        "    D = \"pretrained_v2/D48k.pth\""
      ],
      "metadata": {
        "id": "qSiiUmccYRSo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proprocess dataset and start training"
      ],
      "metadata": {
        "id": "wDc36qTLWJFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Trainset preprocess\n",
        "!python trainset_preprocess_pipeline_print.py $INPDATASET $TARGET_SAMPLE_RATE \"{CPU_THREADS}\" '/content/RVC/logs/{MODELNAME}' False"
      ],
      "metadata": {
        "id": "qeIi_e2OdTtm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract F0\n",
        "if PITCH_GUIDANCE:\n",
        "  !python extract_f0_print.py \"/content/RVC/logs/{MODELNAME}\" \"{CPU_THREADS}\" \"{EXTRACTION_ALGORITHM}\""
      ],
      "metadata": {
        "id": "csb4RD7ZNq9o",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract feature print\n",
        "!python extract_feature_print.py 'cuda:0' '1' \"{GPU_INDEX}\" \"{GPU_INDEX}\" \"/content/RVC/logs/{MODELNAME}\" \"{SAMPLE_RATE_VERSION}\""
      ],
      "metadata": {
        "id": "P3s-7q5pr4je",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start train\n",
        "from random import shuffle\n",
        "if TARGET_SAMPLE_RATE==32000:\n",
        "  TARGET_SAMPLE_RATE=\"32k\"\n",
        "if TARGET_SAMPLE_RATE==40000:\n",
        "  TARGET_SAMPLE_RATE=\"40k\"\n",
        "if TARGET_SAMPLE_RATE==48000:\n",
        "  TARGET_SAMPLE_RATE=\"48k\"\n",
        "\n",
        "\n",
        "\n",
        "if TARGET_SAMPLE_RATE==\"32k\" and SAMPLE_RATE_VERSION==\"v2\":\n",
        "  !cp /content/RVC/configs/32k_v2.json  \"/content/RVC/logs/{MODELNAME}/config.json\"\n",
        "\n",
        "  if PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/f0D32k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/f0G32k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "  if not PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/D32k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/G32k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "\n",
        "if TARGET_SAMPLE_RATE==\"40k\" and SAMPLE_RATE_VERSION==\"v2\":\n",
        "  !cp /content/RVC/configs/40k.json  \"/content/RVC/logs/{MODELNAME}/config.json\"\n",
        "\n",
        "  if PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained_v2/f0D40k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained_v2/f0G40k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "  if not PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained_v2/D40k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained_v2/G40k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "\n",
        "if TARGET_SAMPLE_RATE==\"48k\" and SAMPLE_RATE_VERSION==\"v2\":\n",
        "  !cp /content/RVC/configs/48k_v2.json  \"/content/RVC/logs/{MODELNAME}/config.json\"\n",
        "\n",
        "  if PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/f0D48k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/f0G48k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "  if not PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/D48k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/G48k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if TARGET_SAMPLE_RATE==\"32k\" and SAMPLE_RATE_VERSION==\"v1\":\n",
        "  !cp /content/RVC/configs/32k.json  \"/content/RVC/logs/{MODELNAME}/config.json\"\n",
        "\n",
        "  if PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/f0D32k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/f0G32k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "  if not PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/D32k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/G32k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "\n",
        "if TARGET_SAMPLE_RATE==\"40k\" and SAMPLE_RATE_VERSION==\"v1\":\n",
        "  !cp /content/RVC/configs/40k.json  \"/content/RVC/logs/{MODELNAME}/config.json\"\n",
        "\n",
        "  if PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/f0D40k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/f0G40k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "  if not PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/D40k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/G40k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "\n",
        "if TARGET_SAMPLE_RATE==\"48k\" and SAMPLE_RATE_VERSION==\"v1\":\n",
        "  !cp /content/RVC/configs/48k.json  \"/content/RVC/logs/{MODELNAME}/config.json\"\n",
        "\n",
        "  if PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/f0D48k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/f0G48k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "  if not PITCH_GUIDANCE:\n",
        "    !cp /content/RVC/pretrained/D48k.pth \"/content/RVC/logs/{MODELNAME}/D_0.pth\"\n",
        "    !cp /content/RVC/pretrained/G48k.pth \"/content/RVC/logs/{MODELNAME}/G_0.pth\"\n",
        "\n",
        "\n",
        "with open(f\"./logs/{MODELNAME}/config.json\", \"r\") as f:\n",
        "  config=f.read()\n",
        "\n",
        "config=config.replace('\"log_interval\": 200,', '\"log_interval\": 30,')\n",
        "\n",
        "with open(f\"./logs/{MODELNAME}/config.json\", \"w\") as f:\n",
        "  f.write(config)\n",
        "\n",
        "now_dir = os.getcwd()\n",
        "def click_train(exp_dir1, if_f0_3, spk_id5, version19):\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "\n",
        "click_train(MODELNAME, PITCH_GUIDANCE, Speaker_ID, SAMPLE_RATE_VERSION)\n",
        "!python train_nsf_sim_cache_sid_load_pretrain.py -e \"{MODELNAME}\" -sr \"{TARGET_SAMPLE_RATE}\" -f0 \"{PITCH_GUIDANCE}\" -bs \"{BATCH_SIZE_PER_GPU}\" -g \"{GPU_INDEX}\" -te \"{total_epoch}\" -l \"{SAVE_ONLY_LATEST_CKPT}\" -c \"{CACHE_ALL_TRAINING_SETS_TO_GPU_MEMORY}\" -sw \"{SAVE_A_SMALL_FINAL_MODEL}\" -v \"{SAMPLE_RATE_VERSION}\" -se \"{save_every_epoch}\" #-pg \"{G}\" -pd \"{D}\""
      ],
      "metadata": {
        "id": "JKZIxiiKWsfs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train index\n",
        "import faiss, numpy as np\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import traceback\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "if SAMPLE_RATE_VERSION==\"v1\":\n",
        "  inp_root = \"./logs/{MODELNAME}/3_feature256\"\n",
        "  npys = []\n",
        "  for name in sorted(list(os.listdir(inp_root))):\n",
        "      phone = np.load(\"%s/%s\" % (inp_root, name))\n",
        "      npys.append(phone)\n",
        "  big_npy = np.concatenate(npys, 0)\n",
        "  print(big_npy.shape)  # (6196072, 192)#fp32#4.43G\n",
        "  np.save(\"infer/big_src_feature_mi.npy\", big_npy)\n",
        "\n",
        "  ##################train+add\n",
        "  # big_npy=np.load(\"/bili-coeus/jupyter/jupyterhub-liujing04/vits_ch/inference_f0/big_src_feature_mi.npy\")\n",
        "  print(big_npy.shape)\n",
        "  index = faiss.index_factory(256, \"IVF512,Flat\")  # mi\n",
        "  print(\"training\")\n",
        "  index_ivf = faiss.extract_index_ivf(index)  #\n",
        "  index_ivf.nprobe = 9\n",
        "  index.train(big_npy)\n",
        "  faiss.write_index(index, \"infer/trained_IVF512_Flat_mi_baseline_src_feat.index\")\n",
        "  print(\"adding\")\n",
        "  index.add(big_npy)\n",
        "  faiss.write_index(index, \"infer/added_IVF512_Flat_mi_baseline_src_feat.index\")\n",
        "\n",
        "\n",
        "if SAMPLE_RATE_VERSION==\"v2\":\n",
        "  inp_root = f\"./logs/{MODELNAME}/3_feature768\"\n",
        "  n_cpu = 0\n",
        "  if n_cpu == 0:\n",
        "      n_cpu = cpu_count()\n",
        "  npys = []\n",
        "  listdir_res = list(os.listdir(inp_root))\n",
        "  for name in sorted(listdir_res):\n",
        "      phone = np.load(\"%s/%s\" % (inp_root, name))\n",
        "      npys.append(phone)\n",
        "  big_npy = np.concatenate(npys, 0)\n",
        "  big_npy_idx = np.arange(big_npy.shape[0])\n",
        "  np.random.shuffle(big_npy_idx)\n",
        "  big_npy = big_npy[big_npy_idx]\n",
        "  print(big_npy.shape)  # (6196072, 192)#fp32#4.43G\n",
        "  if big_npy.shape[0] > 2e5:\n",
        "      # if(1):\n",
        "      info = \"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0]\n",
        "      print(info)\n",
        "      try:\n",
        "          big_npy = (\n",
        "              MiniBatchKMeans(\n",
        "                  n_clusters=10000,\n",
        "                  verbose=True,\n",
        "                  batch_size=256 * n_cpu,\n",
        "                  compute_labels=False,\n",
        "                  init=\"random\",\n",
        "              )\n",
        "              .fit(big_npy)\n",
        "              .cluster_centers_\n",
        "          )\n",
        "      except:\n",
        "          info = traceback.format_exc()\n",
        "          print(info)\n",
        "\n",
        "  np.save(\"tools/infer/big_src_feature_mi.npy\", big_npy)\n",
        "\n",
        "  ##################train+add\n",
        "  # big_npy=np.load(\"/bili-coeus/jupyter/jupyterhub-liujing04/vits_ch/inference_f0/big_src_feature_mi.npy\")\n",
        "  n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "  index = faiss.index_factory(768, \"IVF%s,Flat\" % n_ivf)  # mi\n",
        "  print(\"training\")\n",
        "  index_ivf = faiss.extract_index_ivf(index)  #\n",
        "  index_ivf.nprobe = 1\n",
        "  index.train(big_npy)\n",
        "  faiss.write_index(\n",
        "      index, \"tools/infer/trained_IVF%s_Flat_baseline_src_feat_v2.index\" % (n_ivf)\n",
        "  )\n",
        "  print(\"adding\")\n",
        "  batch_size_add = 8192\n",
        "  for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "      index.add(big_npy[i : i + batch_size_add])\n",
        "  faiss.write_index(\n",
        "      index, \"tools/infer/added_IVF%s_Flat_mi_baseline_src_feat.index\" % (n_ivf)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "JPzUnN3te49R",
        "outputId": "6dcbefee-3e13-4a15-8547-a8d08bfc29cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17846, 768)\n",
            "training\n",
            "adding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"/content/drive/MyDrive/ai/{MODELNAME}\"\n",
        "!cp \"./weights/{MODELNAME}.pth\" \"/content/drive/MyDrive/ai/{MODELNAME}/.\"\n",
        "!cp \"./tools/infer/*.index\" \"/content/drive/MyDrive/ai/{MODELNAME}/.\""
      ],
      "metadata": {
        "id": "b3yFXadt-pe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n"
      ],
      "metadata": {
        "id": "-sgUeX-xWbNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference (BETA)\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "%cd /content/RVC\n",
        "\n",
        "file_path = \"ai/sounds/\" #@param {type:\"string\"}\n",
        "output_file_path = \"ai/sounds/out/\" #@param {type:\"string\"}\n",
        "spk_id = 0 # @param {type:\"slider\", min:0, max:5, step:1}\n",
        "index = \"None\" #@param {type:\"string\"}\n",
        "EA = \"harvest\" # @param [\"harvest\", \"dio\", \"pm\"]\n",
        "pth_path = \"ai/PITONAI/PITONAI.pth\" #@param {type:\"string\"}\n",
        "median_filtering = 3 # @param {type:\"slider\", min:0, max:7, step:1}\n",
        "resample_audio = 0 # @param {type:\"slider\", min:0, max:48000, step:1}\n",
        "protect_voiceless = 0.15 # @param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "index_rate = 0 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "mimics_volume_rate = 1 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "pth_path = \"/content/drive/MyDrive/\" + pth_path\n",
        "index = \"/content/drive/MyDrive/\" + index\n",
        "filename=file_path\n",
        "file_path = \"/content/drive/MyDrive/\" + file_path\n",
        "output_file_path = \"/content/drive/MyDrive/\" + output_file_path\n",
        "clear_output()\n",
        "#!python infer_batch_rvc.py \"{spk_id}\" \"{file_path}\" \"{index}\" \"{EA}\" \"{output_file_path}\" \"{pth_path}\" \"{index_rate}\" cuda:0 True \"{median_filtering}\" \"{resample_audio}\" \"{mimics_volume_rate}\" \"{protect_voiceless}\"\n",
        "!python infer_batch_rvc.py 0 \"/content/drive/MyDrive/ai/sounds/\" \"None\" harvest \"/content/drive/MyDrive/ai/sounds/out\" \"/content/drive/MyDrive/ai/PITONAI/PITONAI.pth\" 0.66 cuda:0 True 3 0 1 0.33\n",
        "time.sleep(1)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zNpoP44nWlaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc"
      ],
      "metadata": {
        "id": "otjrpJm4gcTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run in web using Gradio\n",
        "!python infer-web.py --colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "LTZDxcexIIC_",
        "outputId": "0acab6d2-c650-42ca-9a17-184ac48f87d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 19:02:52.635218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-12 19:02:54.089861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Found GPU Tesla T4\n",
            "Use Language: en_US\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "Setting up a public link... we have recently upgraded the way public links are generated. If you encounter any problems, please report the issue and downgrade to gradio version 3.13.0\n",
            ".\n",
            "Running on public URL: https://6f7a8f0c-67eb-4741.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "loading weights/PITONAI.pth\n",
            "gin_channels: 256 self.spk_embed_dim: 109\n",
            "<All keys matched successfully>\n",
            "2023-08-12 19:04:09 | INFO | fairseq.tasks.hubert_pretraining | current directory is /content/RVC\n",
            "2023-08-12 19:04:09 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
            "2023-08-12 19:04:09 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n",
            "clean_empty_cache\n",
            "gin_channels: 256 self.spk_embed_dim: 109\n",
            "loading weights/PITONAI.pth\n",
            "gin_channels: 256 self.spk_embed_dim: 109\n",
            "<All keys matched successfully>\n",
            "2023-08-12 19:06:56 | INFO | fairseq.tasks.hubert_pretraining | current directory is /content/RVC\n",
            "2023-08-12 19:06:56 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
            "2023-08-12 19:06:56 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n",
            "loading weights/PITONAI_e10_s100.pth\n",
            "gin_channels: 256 self.spk_embed_dim: 109\n",
            "<All keys matched successfully>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export onnx\n",
        "%cd /content/RVC/\n",
        "\n",
        "MODELNAME2 = \"PITONAI\" #@param {type:\"string\"}\n",
        "\n",
        "from lib.infer_pack.models_onnx import SynthesizerTrnMsNSFsidM\n",
        "import torch\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MoeVS = True  # 模型是否为MoeVoiceStudio（原MoeSS）使用\n",
        "\n",
        "    ModelPath = f\"weights/{MODELNAME2}.pth\"  # 模型路径\n",
        "    ExportedPath = \"model.onnx\"  # 输出路径\n",
        "    hidden_channels = 256  # hidden_channels，为768Vec做准备\n",
        "    cpt = torch.load(ModelPath, map_location=\"cpu\")\n",
        "    cpt[\"config\"][-3] = cpt[\"weight\"][\"emb_g.weight\"].shape[0]  # n_spk\n",
        "    print(*cpt[\"config\"])\n",
        "\n",
        "    test_phone = torch.rand(1, 200, hidden_channels)  # hidden unit\n",
        "    test_phone_lengths = torch.tensor([200]).long()  # hidden unit 长度（貌似没啥用）\n",
        "    test_pitch = torch.randint(size=(1, 200), low=5, high=255)  # 基频（单位赫兹）\n",
        "    test_pitchf = torch.rand(1, 200)  # nsf基频\n",
        "    test_ds = torch.LongTensor([0])  # 说话人ID\n",
        "    test_rnd = torch.rand(1, 192, 200)  # 噪声（加入随机因子）\n",
        "\n",
        "    device = \"cpu\"  # 导出时设备（不影响使用模型）\n",
        "\n",
        "    net_g = SynthesizerTrnMsNSFsidM(\n",
        "        *cpt[\"config\"], is_half=False\n",
        "    )  # fp32导出（C++要支持fp16必须手动将内存重新排列所以暂时不用fp16）\n",
        "    net_g.load_state_dict(cpt[\"weight\"], strict=False)\n",
        "    input_names = [\"phone\", \"phone_lengths\", \"pitch\", \"pitchf\", \"ds\", \"rnd\"]\n",
        "    output_names = [\n",
        "        \"audio\",\n",
        "    ]\n",
        "    # net_g.construct_spkmixmap(n_speaker) 多角色混合轨道导出\n",
        "    torch.onnx.export(\n",
        "        net_g,\n",
        "        (\n",
        "            test_phone.to(device),\n",
        "            test_phone_lengths.to(device),\n",
        "            test_pitch.to(device),\n",
        "            test_pitchf.to(device),\n",
        "            test_ds.to(device),\n",
        "            test_rnd.to(device),\n",
        "        ),\n",
        "        ExportedPath,\n",
        "        dynamic_axes={\n",
        "            \"phone\": [1],\n",
        "            \"pitch\": [1],\n",
        "            \"pitchf\": [1],\n",
        "            \"rnd\": [2],\n",
        "        },\n",
        "        do_constant_folding=False,\n",
        "        opset_version=16,\n",
        "        verbose=False,\n",
        "        input_names=input_names,\n",
        "        output_names=output_names,\n",
        "    )\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DpPLUrERgfDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}